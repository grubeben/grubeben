# Servus or Hey there!

Welcome to my Github âœ¨
I am about to finish my masters degree in CSE (Computational Science and Engineering) at [TU Wien](https://www.tuwien.at/) in Vienna, Austria. My B.Sc was in Mechanical Engineering and Management, also at TU Wien - I was part of exchange programs to [ETH ZÃ¼rich](https://www.ethz.ch/), [Chalmers](https://www.chalmers.se/) and most recently a visiting researcher at the [University of California - Santa Barbara](https://www.ucsb.edu/) for my M.Sc thesis. 

Best way to reach out to me would be at [/in/grubeben](https://www.linkedin.com/in/benjamin-gruber-4817781a1/), even though I am not on the platform regularly.

Most of my university projects are in private repos, but some are available here (_or somewhat available_ ğŸ³).

## ğŸ¤–[Reinforcement Learning - Advantage-Actor-Critic (A2C) implementation](https://github.com/grubeben/194.077-Applied-Deep-Learning)ğŸ¤–

In a prior internship with Bosch I implemented a â€™Deep-Qâ€™ reinforcement-learning algorithm to optimize energy-contribution from combustion- and electric engine in hybrid vehicles (code is unfortunately not publicly available). While the â€™Deep-Qâ€™ algorithm features a single neural network and is purely value-based (the algorithm learns the state or state-action value), I wanted to investifate policy-based reinforcement learning (the algorithm directly learns the policy rather than the state values). As part of my Applied Deep Learning seminar project at TU Wien I implemented an Advantage-Actor-Critic(A2C) reinforcement learning agent which comprises two neural networks (the actor and the critic where the latter learns the state or state-action value and the former directly learns a policy). I employed two agent versions (discrete vs. continous state space) in a couple of openAI-gym environments and investigated how input normalization and activation functions change the learning speed. The continous-state-space version proved to be much harder to implement and struggles to arrive at a converged policy.

You can find a short video presentation of the porject [here](https://www.youtube.com/watch?v=bbEv1J6oSts).

<img src="https://github.com/grubeben/194.077-Applied-Deep-Learning/blob/main/obs-samples/rewards_over_time_a2c_discrete.PNG?raw=true" width="500">

_The A2C-agents trainings success for different agent configurations_

## ğŸš•[XXXX](https://github.com/grubeben/grubeben)ğŸš•
My most interesting work is in the field of **Topological Data Analysis**.
My B.Sc thesis in Applied Mathematics was done at the University of Nairobi and Uber Technologies in Kenya.

![Link xxx](https://github.com/grubeben/xxx.png?raw=true "Barcoding Nairobi")


## ğŸ“ˆ[OsÃ¤ker osÃ¤kerhet](https://github.com/EricBojs/Osaker-osakerhet)ğŸ“ˆ
You'll also find a project on financial modelling using Python. The project is in the form of a workbook using Colab/Jupyter Notebook teaching the reader how to download financial data, model financial claims and calculating volatilities (implied and historical). Unfortunely (?), it is only available for the Swedish speaker...

<img src="https://github.com/grubeben/xxx.png?raw=true" width="500">


<!--
**grubeben/grubeben** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
